{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Greetings! \n",
    "\n",
    "In the next steps I'll show how I would usually approach analyzing new data, ingesting and transforming/aggregating the data into useful info for the final user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\users\\ritter\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (22.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade pip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: boto3 in c:\\users\\ritter\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (1.25.4)\n",
      "Collecting pandas\n",
      "  Downloading pandas-1.5.1-cp310-cp310-win_amd64.whl (10.4 MB)\n",
      "     --------------------------------------- 10.4/10.4 MB 10.1 MB/s eta 0:00:00\n",
      "Collecting s3fs\n",
      "  Downloading s3fs-2022.10.0-py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in c:\\users\\ritter\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from boto3) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in c:\\users\\ritter\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from boto3) (0.6.0)\n",
      "Requirement already satisfied: botocore<1.29.0,>=1.28.4 in c:\\users\\ritter\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from boto3) (1.28.4)\n",
      "Collecting numpy>=1.21.0\n",
      "  Downloading numpy-1.23.4-cp310-cp310-win_amd64.whl (14.6 MB)\n",
      "     ---------------------------------------- 14.6/14.6 MB 5.8 MB/s eta 0:00:00\n",
      "Collecting pytz>=2020.1\n",
      "  Downloading pytz-2022.5-py2.py3-none-any.whl (500 kB)\n",
      "     ------------------------------------- 500.7/500.7 kB 32.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\ritter\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pandas) (2.8.2)\n",
      "Collecting fsspec==2022.10.0\n",
      "  Downloading fsspec-2022.10.0-py3-none-any.whl (138 kB)\n",
      "     -------------------------------------- 138.8/138.8 kB 8.0 MB/s eta 0:00:00\n",
      "Collecting aiobotocore~=2.4.0\n",
      "  Downloading aiobotocore-2.4.0-py3-none-any.whl (65 kB)\n",
      "     ---------------------------------------- 65.8/65.8 kB 3.5 MB/s eta 0:00:00\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1\n",
      "  Downloading aiohttp-3.8.3-cp310-cp310-win_amd64.whl (319 kB)\n",
      "     ------------------------------------- 319.7/319.7 kB 19.3 MB/s eta 0:00:00\n",
      "INFO: pip is looking at multiple versions of fsspec to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of s3fs to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting s3fs\n",
      "  Downloading s3fs-2022.8.2-py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in c:\\users\\ritter\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from botocore<1.29.0,>=1.28.4->boto3) (1.26.12)\n",
      "Collecting fsspec==2022.8.2\n",
      "  Downloading fsspec-2022.8.2-py3-none-any.whl (140 kB)\n",
      "     -------------------------------------- 140.8/140.8 kB 8.2 MB/s eta 0:00:00\n",
      "Collecting s3fs\n",
      "  Downloading s3fs-2022.8.1-py3-none-any.whl (27 kB)\n",
      "Collecting fsspec==2022.8.1\n",
      "  Downloading fsspec-2022.8.1-py3-none-any.whl (140 kB)\n",
      "     -------------------------------------- 140.8/140.8 kB 8.2 MB/s eta 0:00:00\n",
      "Collecting s3fs\n",
      "  Downloading s3fs-2022.8.0-py3-none-any.whl (27 kB)\n",
      "Collecting fsspec==2022.8.0\n",
      "  Downloading fsspec-2022.8.0-py3-none-any.whl (140 kB)\n",
      "     ---------------------------------------- 141.0/141.0 kB ? eta 0:00:00\n",
      "Collecting s3fs\n",
      "  Downloading s3fs-2022.7.1-py3-none-any.whl (27 kB)\n",
      "Collecting fsspec==2022.7.1\n",
      "  Downloading fsspec-2022.7.1-py3-none-any.whl (141 kB)\n",
      "     -------------------------------------- 141.2/141.2 kB 8.7 MB/s eta 0:00:00\n",
      "Collecting aiobotocore~=2.3.4\n",
      "  Downloading aiobotocore-2.3.4-py3-none-any.whl (64 kB)\n",
      "     ---------------------------------------- 64.7/64.7 kB 3.4 MB/s eta 0:00:00\n",
      "Collecting s3fs\n",
      "  Downloading s3fs-2022.7.0-py3-none-any.whl (27 kB)\n",
      "Collecting fsspec==2022.7.0\n",
      "  Downloading fsspec-2022.7.0-py3-none-any.whl (141 kB)\n",
      "     ---------------------------------------- 141.2/141.2 kB ? eta 0:00:00\n",
      "Collecting s3fs\n",
      "  Downloading s3fs-2022.5.0-py3-none-any.whl (27 kB)\n",
      "Collecting fsspec==2022.5.0\n",
      "  Downloading fsspec-2022.5.0-py3-none-any.whl (140 kB)\n",
      "     ---------------------------------------- 140.6/140.6 kB ? eta 0:00:00\n",
      "Collecting aiobotocore~=2.3.0\n",
      "  Downloading aiobotocore-2.3.3.tar.gz (65 kB)\n",
      "     ---------------------------------------- 65.7/65.7 kB ? eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "  Downloading aiobotocore-2.3.2.tar.gz (104 kB)\n",
      "     -------------------------------------- 104.8/104.8 kB 5.9 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "  Downloading aiobotocore-2.3.1.tar.gz (65 kB)\n",
      "     ---------------------------------------- 65.3/65.3 kB ? eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "  Downloading aiobotocore-2.3.0.tar.gz (65 kB)\n",
      "     ---------------------------------------- 65.1/65.1 kB ? eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting s3fs\n",
      "  Downloading s3fs-2022.3.0-py3-none-any.whl (26 kB)\n",
      "Collecting aiobotocore~=2.2.0\n",
      "  Downloading aiobotocore-2.2.0.tar.gz (59 kB)\n",
      "     ---------------------------------------- 59.7/59.7 kB 3.1 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting fsspec==2022.3.0\n",
      "  Downloading fsspec-2022.3.0-py3-none-any.whl (136 kB)\n",
      "     -------------------------------------- 136.1/136.1 kB 7.9 MB/s eta 0:00:00\n",
      "INFO: pip is looking at multiple versions of fsspec to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of s3fs to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting s3fs\n",
      "  Downloading s3fs-2022.2.0-py3-none-any.whl (26 kB)\n",
      "Collecting fsspec==2022.02.0\n",
      "  Downloading fsspec-2022.2.0-py3-none-any.whl (134 kB)\n",
      "     ---------------------------------------- 134.9/134.9 kB ? eta 0:00:00\n",
      "Collecting aiobotocore~=2.1.0\n",
      "  Downloading aiobotocore-2.1.2.tar.gz (58 kB)\n",
      "     ---------------------------------------- 58.7/58.7 kB 3.2 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "  Downloading aiobotocore-2.1.1.tar.gz (57 kB)\n",
      "     ---------------------------------------- 57.5/57.5 kB 3.0 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "  Downloading aiobotocore-2.1.0.tar.gz (54 kB)\n",
      "     ---------------------------------------- 54.6/54.6 kB ? eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting s3fs\n",
      "  Downloading s3fs-2022.1.0-py3-none-any.whl (25 kB)\n",
      "Collecting fsspec==2022.01.0\n",
      "  Downloading fsspec-2022.1.0-py3-none-any.whl (133 kB)\n",
      "     ---------------------------------------- 133.2/133.2 kB ? eta 0:00:00\n",
      "Collecting s3fs\n",
      "  Downloading s3fs-2021.11.1-py3-none-any.whl (25 kB)\n",
      "Collecting aiobotocore~=2.0.1\n",
      "  Downloading aiobotocore-2.0.1.tar.gz (54 kB)\n",
      "     ---------------------------------------- 54.5/54.5 kB ? eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting fsspec==2021.11.1\n",
      "  Downloading fsspec-2021.11.1-py3-none-any.whl (132 kB)\n",
      "     ---------------------------------------- 133.0/133.0 kB ? eta 0:00:00\n",
      "Collecting s3fs\n",
      "  Downloading s3fs-2021.11.0-py3-none-any.whl (25 kB)\n",
      "Collecting fsspec==2021.11.0\n",
      "  Downloading fsspec-2021.11.0-py3-none-any.whl (132 kB)\n",
      "     -------------------------------------- 132.4/132.4 kB 7.6 MB/s eta 0:00:00\n",
      "Collecting aiobotocore~=1.4.1\n",
      "  Downloading aiobotocore-1.4.2.tar.gz (52 kB)\n",
      "     ---------------------------------------- 52.5/52.5 kB 2.8 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "  Downloading aiobotocore-1.4.1.tar.gz (52 kB)\n",
      "     ---------------------------------------- 52.3/52.3 kB 2.6 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting s3fs\n",
      "  Downloading s3fs-2021.10.1-py3-none-any.whl (26 kB)\n",
      "Collecting fsspec==2021.10.1\n",
      "  Downloading fsspec-2021.10.1-py3-none-any.whl (125 kB)\n",
      "     -------------------------------------- 125.6/125.6 kB 7.7 MB/s eta 0:00:00\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "Collecting s3fs\n",
      "  Downloading s3fs-2021.10.0-py3-none-any.whl (26 kB)\n",
      "Collecting fsspec==2021.10.0\n",
      "  Downloading fsspec-2021.10.0-py3-none-any.whl (125 kB)\n",
      "     -------------------------------------- 125.0/125.0 kB 7.7 MB/s eta 0:00:00\n",
      "Collecting s3fs\n",
      "  Downloading s3fs-2021.9.0-py3-none-any.whl (26 kB)\n",
      "Collecting fsspec==2021.09.0\n",
      "  Downloading fsspec-2021.9.0-py3-none-any.whl (123 kB)\n",
      "     -------------------------------------- 123.6/123.6 kB 7.1 MB/s eta 0:00:00\n",
      "Collecting s3fs\n",
      "  Downloading s3fs-2021.8.1-py3-none-any.whl (26 kB)\n",
      "Collecting fsspec==2021.08.1\n",
      "  Downloading fsspec-2021.8.1-py3-none-any.whl (119 kB)\n",
      "     -------------------------------------- 119.3/119.3 kB 6.8 MB/s eta 0:00:00\n",
      "Collecting aiobotocore~=1.4.0\n",
      "  Downloading aiobotocore-1.4.0.tar.gz (51 kB)\n",
      "     ---------------------------------------- 51.6/51.6 kB ? eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting s3fs\n",
      "  Downloading s3fs-2021.8.0-py3-none-any.whl (26 kB)\n",
      "Collecting fsspec==2021.07.0\n",
      "  Downloading fsspec-2021.7.0-py3-none-any.whl (118 kB)\n",
      "     ---------------------------------------- 118.1/118.1 kB ? eta 0:00:00\n",
      "Collecting s3fs\n",
      "  Downloading s3fs-2021.7.0-py3-none-any.whl (25 kB)\n",
      "Collecting aiobotocore>=1.0.1\n",
      "  Downloading aiobotocore-2.0.0.tar.gz (52 kB)\n",
      "     ---------------------------------------- 53.0/53.0 kB ? eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "  Downloading aiobotocore-1.3.3.tar.gz (50 kB)\n",
      "     ---------------------------------------- 50.6/50.6 kB 2.5 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "  Downloading aiobotocore-1.3.2.tar.gz (49 kB)\n",
      "     ---------------------------------------- 49.1/49.1 kB 2.6 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "  Downloading aiobotocore-1.3.1.tar.gz (48 kB)\n",
      "     ---------------------------------------- 48.8/48.8 kB ? eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "  Downloading aiobotocore-1.3.0.tar.gz (48 kB)\n",
      "     ---------------------------------------- 48.2/48.2 kB ? eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "  Downloading aiobotocore-1.2.2.tar.gz (48 kB)\n",
      "     ---------------------------------------- 48.1/48.1 kB ? eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "  Downloading aiobotocore-1.2.1.tar.gz (48 kB)\n",
      "     ---------------------------------------- 48.0/48.0 kB 2.4 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "  Downloading aiobotocore-1.2.0.tar.gz (47 kB)\n",
      "     ---------------------------------------- 47.3/47.3 kB 2.3 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "  Downloading aiobotocore-1.1.2-py3-none-any.whl (45 kB)\n",
      "     ---------------------------------------- 45.1/45.1 kB ? eta 0:00:00\n",
      "Collecting wrapt>=1.10.10\n",
      "  Downloading wrapt-1.14.1-cp310-cp310-win_amd64.whl (35 kB)\n",
      "Collecting aioitertools>=0.5.1\n",
      "  Downloading aioitertools-0.11.0-py3-none-any.whl (23 kB)\n",
      "Collecting aiobotocore>=1.0.1\n",
      "  Downloading aiobotocore-1.1.1-py3-none-any.whl (45 kB)\n",
      "     ---------------------------------------- 45.0/45.0 kB ? eta 0:00:00\n",
      "  Downloading aiobotocore-1.1.0-py3-none-any.whl (43 kB)\n",
      "     ---------------------------------------- 43.7/43.7 kB 2.2 MB/s eta 0:00:00\n",
      "  Downloading aiobotocore-1.0.7-py3-none-any.whl (42 kB)\n",
      "     ---------------------------------------- 42.9/42.9 kB ? eta 0:00:00\n",
      "  Downloading aiobotocore-1.0.6-py3-none-any.whl (42 kB)\n",
      "     ---------------------------------------- 42.1/42.1 kB ? eta 0:00:00\n",
      "  Downloading aiobotocore-1.0.5-py3-none-any.whl (42 kB)\n",
      "     ---------------------------------------- 42.1/42.1 kB ? eta 0:00:00\n",
      "  Downloading aiobotocore-1.0.4-py3-none-any.whl (41 kB)\n",
      "     ---------------------------------------- 41.6/41.6 kB ? eta 0:00:00\n",
      "  Downloading aiobotocore-1.0.3-py3-none-any.whl (40 kB)\n",
      "     ---------------------------------------- 40.8/40.8 kB 1.9 MB/s eta 0:00:00\n",
      "  Downloading aiobotocore-1.0.2-py3-none-any.whl (40 kB)\n",
      "     ---------------------------------------- 40.8/40.8 kB ? eta 0:00:00\n",
      "  Downloading aiobotocore-1.0.1-py3-none-any.whl (40 kB)\n",
      "     ---------------------------------------- 40.7/40.7 kB ? eta 0:00:00\n",
      "Collecting s3fs\n",
      "  Downloading s3fs-2021.6.1-py3-none-any.whl (25 kB)\n",
      "Collecting fsspec==2021.06.1\n",
      "  Downloading fsspec-2021.6.1-py3-none-any.whl (115 kB)\n",
      "     ---------------------------------------- 115.1/115.1 kB ? eta 0:00:00\n",
      "Collecting s3fs\n",
      "  Downloading s3fs-2021.6.0-py3-none-any.whl (24 kB)\n",
      "Collecting fsspec==2021.06.0\n",
      "  Downloading fsspec-2021.6.0-py3-none-any.whl (114 kB)\n",
      "     -------------------------------------- 114.7/114.7 kB 7.0 MB/s eta 0:00:00\n",
      "Collecting s3fs\n",
      "  Downloading s3fs-2021.5.0-py3-none-any.whl (24 kB)\n",
      "Collecting fsspec==2021.05.0\n",
      "  Downloading fsspec-2021.5.0-py3-none-any.whl (111 kB)\n",
      "     -------------------------------------- 111.7/111.7 kB 6.8 MB/s eta 0:00:00\n",
      "Collecting s3fs\n",
      "  Downloading s3fs-2021.4.0-py3-none-any.whl (23 kB)\n",
      "Collecting fsspec==2021.04.0\n",
      "  Downloading fsspec-2021.4.0-py3-none-any.whl (108 kB)\n",
      "     ---------------------------------------- 108.3/108.3 kB ? eta 0:00:00\n",
      "Collecting s3fs\n",
      "  Downloading s3fs-0.6.0-py3-none-any.whl (23 kB)\n",
      "  Downloading s3fs-0.5.2-py3-none-any.whl (22 kB)\n",
      "  Downloading s3fs-0.5.1-py3-none-any.whl (21 kB)\n",
      "  Downloading s3fs-0.5.0-py3-none-any.whl (21 kB)\n",
      "  Downloading s3fs-0.4.2-py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ritter\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Installing collected packages: pytz, numpy, fsspec, pandas, s3fs\n",
      "Successfully installed fsspec-2022.10.0 numpy-1.23.4 pandas-1.5.1 pytz-2022.5 s3fs-0.4.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script f2py.exe is installed in 'C:\\Users\\Ritter\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    }
   ],
   "source": [
    "pip install boto3 pandas s3fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import boto3\n",
    "import pandas as pd\n",
    "\n",
    "#Probably would use boto3 or the aws sdk to access the files properly with the credentials config\n",
    "\n",
    "#s3 = boto3.client('s3',\n",
    "#         aws_access_key_id='ACCESS_ID',\n",
    "#         aws_secret_access_key= 'ACCESS_KEY')\n",
    "#people = s3.get_object(Bucket='contrary-engineering-interview.s3.amazonaws.com', Key='data/people.csv')\n",
    "#companies = s3.get_object(Bucket='contrary-engineering-interview.s3.amazonaws.com', Key='data/companies.csv')\n",
    "\n",
    "people_df = pd.read_csv('https://contrary-engineering-interview.s3.amazonaws.com/data/people.csv')\n",
    "companies_df = pd.read_csv('https://contrary-engineering-interview.s3.amazonaws.com/data/companies.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PERSON_ID</th>\n",
       "      <th>COMPANY_NAME</th>\n",
       "      <th>COMPANY_LI_NAME</th>\n",
       "      <th>LAST_TITLE</th>\n",
       "      <th>GROUP_START_DATE</th>\n",
       "      <th>GROUP_END_DATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9fb750ce-4acd-40d6-a58b-f6718342364f</td>\n",
       "      <td>GoCardless</td>\n",
       "      <td>gocardless</td>\n",
       "      <td>Software Engineer</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>2020-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9fb750ce-4acd-40d6-a58b-f6718342364f</td>\n",
       "      <td>Stealth startup</td>\n",
       "      <td>online-shoe-store</td>\n",
       "      <td>Founder / CTO</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>2019-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9fb750ce-4acd-40d6-a58b-f6718342364f</td>\n",
       "      <td>Arkera</td>\n",
       "      <td>arkera</td>\n",
       "      <td>Software Engineer</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>2018-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9fb750ce-4acd-40d6-a58b-f6718342364f</td>\n",
       "      <td>Imperial College London</td>\n",
       "      <td>imperial-college-london</td>\n",
       "      <td>UTA (Undergraduate Teaching Assistant)</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>2017-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15f5d8ed-36ad-4cf7-8748-c50dc9589f59</td>\n",
       "      <td>Splunk</td>\n",
       "      <td>splunk</td>\n",
       "      <td>Software Engineer</td>\n",
       "      <td>2019-10-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5386</th>\n",
       "      <td>341cd181-1e2f-4198-b5b4-928475c17120</td>\n",
       "      <td>L Brands</td>\n",
       "      <td>lbrands</td>\n",
       "      <td>Infosys Consultant</td>\n",
       "      <td>2014-05-01</td>\n",
       "      <td>2014-09-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5387</th>\n",
       "      <td>341cd181-1e2f-4198-b5b4-928475c17120</td>\n",
       "      <td>Gap Inc.</td>\n",
       "      <td>gap-inc-</td>\n",
       "      <td>Infosys Consultant</td>\n",
       "      <td>2012-03-01</td>\n",
       "      <td>2014-03-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5388</th>\n",
       "      <td>341cd181-1e2f-4198-b5b4-928475c17120</td>\n",
       "      <td>Infosys</td>\n",
       "      <td>infosys</td>\n",
       "      <td>Systems Engineer</td>\n",
       "      <td>2011-06-01</td>\n",
       "      <td>2014-09-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5389</th>\n",
       "      <td>341cd181-1e2f-4198-b5b4-928475c17120</td>\n",
       "      <td>The Wind Energy Group ITESM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Research Assistant</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>2010-12-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5390</th>\n",
       "      <td>341cd181-1e2f-4198-b5b4-928475c17120</td>\n",
       "      <td>ITESM Campus Monterrey</td>\n",
       "      <td>itesm-campus-monterrey</td>\n",
       "      <td>Teaching Assistant</td>\n",
       "      <td>2007-08-01</td>\n",
       "      <td>2008-12-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5391 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 PERSON_ID                 COMPANY_NAME  \\\n",
       "0     9fb750ce-4acd-40d6-a58b-f6718342364f                   GoCardless   \n",
       "1     9fb750ce-4acd-40d6-a58b-f6718342364f              Stealth startup   \n",
       "2     9fb750ce-4acd-40d6-a58b-f6718342364f                       Arkera   \n",
       "3     9fb750ce-4acd-40d6-a58b-f6718342364f      Imperial College London   \n",
       "4     15f5d8ed-36ad-4cf7-8748-c50dc9589f59                       Splunk   \n",
       "...                                    ...                          ...   \n",
       "5386  341cd181-1e2f-4198-b5b4-928475c17120                     L Brands   \n",
       "5387  341cd181-1e2f-4198-b5b4-928475c17120                     Gap Inc.   \n",
       "5388  341cd181-1e2f-4198-b5b4-928475c17120                      Infosys   \n",
       "5389  341cd181-1e2f-4198-b5b4-928475c17120  The Wind Energy Group ITESM   \n",
       "5390  341cd181-1e2f-4198-b5b4-928475c17120       ITESM Campus Monterrey   \n",
       "\n",
       "              COMPANY_LI_NAME                              LAST_TITLE  \\\n",
       "0                  gocardless                       Software Engineer   \n",
       "1           online-shoe-store                           Founder / CTO   \n",
       "2                      arkera                       Software Engineer   \n",
       "3     imperial-college-london  UTA (Undergraduate Teaching Assistant)   \n",
       "4                      splunk                       Software Engineer   \n",
       "...                       ...                                     ...   \n",
       "5386                  lbrands                      Infosys Consultant   \n",
       "5387                 gap-inc-                      Infosys Consultant   \n",
       "5388                  infosys                        Systems Engineer   \n",
       "5389                      NaN                      Research Assistant   \n",
       "5390   itesm-campus-monterrey                      Teaching Assistant   \n",
       "\n",
       "     GROUP_START_DATE GROUP_END_DATE  \n",
       "0          2019-01-01     2020-01-01  \n",
       "1          2018-01-01     2019-01-01  \n",
       "2          2017-01-01     2018-01-01  \n",
       "3          2016-01-01     2017-01-01  \n",
       "4          2019-10-01            NaN  \n",
       "...               ...            ...  \n",
       "5386       2014-05-01     2014-09-01  \n",
       "5387       2012-03-01     2014-03-01  \n",
       "5388       2011-06-01     2014-09-01  \n",
       "5389       2010-01-01     2010-12-01  \n",
       "5390       2007-08-01     2008-12-01  \n",
       "\n",
       "[5391 rows x 6 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Getting a glimpse into the people.csv file\n",
    "people_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NAME</th>\n",
       "      <th>COMPANY_LINKEDIN_NAMES</th>\n",
       "      <th>DESCRIPTION</th>\n",
       "      <th>HEADCOUNT</th>\n",
       "      <th>FOUNDING_DATE</th>\n",
       "      <th>MOST_RECENT_RAISE</th>\n",
       "      <th>MOST_RECENT_VALUATION</th>\n",
       "      <th>INVESTORS</th>\n",
       "      <th>KNOWN_TOTAL_FUNDING</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ORSYP</td>\n",
       "      <td>[\\n  \"orsyp\"\\n]</td>\n",
       "      <td>IT Operations Management Specialists At ORSYP ...</td>\n",
       "      <td>63.0</td>\n",
       "      <td>1986-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Runwal</td>\n",
       "      <td>[\\n  \"runwal\"\\n]</td>\n",
       "      <td>The Runwal Group was established in 1978 by it...</td>\n",
       "      <td>406.0</td>\n",
       "      <td>1978-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[\\n  \"Brand Capital\"\\n]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Toast</td>\n",
       "      <td>[\\n  \"toast-inc\"\\n]</td>\n",
       "      <td>Toast empowers restaurants of all sizes to bui...</td>\n",
       "      <td>3580.0</td>\n",
       "      <td>2011-12-22</td>\n",
       "      <td>400000000.0</td>\n",
       "      <td>4.900000e+09</td>\n",
       "      <td>[\\n  \"Eight Roads Ventures\",\\n  \"Greenoaks Cap...</td>\n",
       "      <td>899000000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DNA Medicine Institute</td>\n",
       "      <td>[\\n  \"dna-medicine-institute\"\\n]</td>\n",
       "      <td>The DNA Medicine Institute, Inc. (DMI) is a me...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2004-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ally</td>\n",
       "      <td>[\\n  \"ally\"\\n]</td>\n",
       "      <td>Ally Financial Inc. (NYSE: ALLY) is a leading ...</td>\n",
       "      <td>12120.0</td>\n",
       "      <td>1919-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10706</th>\n",
       "      <td>Fidem LLC</td>\n",
       "      <td>[]</td>\n",
       "      <td>We are focused on creating telemedicine apps t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2014-10-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10707</th>\n",
       "      <td>Service Revolution</td>\n",
       "      <td>[\\n  \"%EF%BC%88%E6%A0%AA%EF%BC%89%E3%82%B5%E3%...</td>\n",
       "      <td>Service Revolution is a software development c...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2009-02-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10708</th>\n",
       "      <td>Phelen</td>\n",
       "      <td>[]</td>\n",
       "      <td>Phelen is the personnal holding of Rémi Voluer...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-07-23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10709</th>\n",
       "      <td>Cura Investment</td>\n",
       "      <td>[]</td>\n",
       "      <td>Cura Investment offers real estate investment ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2002-09-28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10710</th>\n",
       "      <td>Beeldstijl Ontwerpstudio</td>\n",
       "      <td>[]</td>\n",
       "      <td>Beeldstijl Ontwerpstudio is an advertising age...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2008-04-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10711 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           NAME  \\\n",
       "0                         ORSYP   \n",
       "1                        Runwal   \n",
       "2                         Toast   \n",
       "3        DNA Medicine Institute   \n",
       "4                          Ally   \n",
       "...                         ...   \n",
       "10706                 Fidem LLC   \n",
       "10707        Service Revolution   \n",
       "10708                    Phelen   \n",
       "10709           Cura Investment   \n",
       "10710  Beeldstijl Ontwerpstudio   \n",
       "\n",
       "                                  COMPANY_LINKEDIN_NAMES  \\\n",
       "0                                        [\\n  \"orsyp\"\\n]   \n",
       "1                                       [\\n  \"runwal\"\\n]   \n",
       "2                                    [\\n  \"toast-inc\"\\n]   \n",
       "3                       [\\n  \"dna-medicine-institute\"\\n]   \n",
       "4                                         [\\n  \"ally\"\\n]   \n",
       "...                                                  ...   \n",
       "10706                                                 []   \n",
       "10707  [\\n  \"%EF%BC%88%E6%A0%AA%EF%BC%89%E3%82%B5%E3%...   \n",
       "10708                                                 []   \n",
       "10709                                                 []   \n",
       "10710                                                 []   \n",
       "\n",
       "                                             DESCRIPTION  HEADCOUNT  \\\n",
       "0      IT Operations Management Specialists At ORSYP ...       63.0   \n",
       "1      The Runwal Group was established in 1978 by it...      406.0   \n",
       "2      Toast empowers restaurants of all sizes to bui...     3580.0   \n",
       "3      The DNA Medicine Institute, Inc. (DMI) is a me...        2.0   \n",
       "4      Ally Financial Inc. (NYSE: ALLY) is a leading ...    12120.0   \n",
       "...                                                  ...        ...   \n",
       "10706  We are focused on creating telemedicine apps t...        NaN   \n",
       "10707  Service Revolution is a software development c...        NaN   \n",
       "10708  Phelen is the personnal holding of Rémi Voluer...        NaN   \n",
       "10709  Cura Investment offers real estate investment ...        NaN   \n",
       "10710  Beeldstijl Ontwerpstudio is an advertising age...        NaN   \n",
       "\n",
       "      FOUNDING_DATE  MOST_RECENT_RAISE  MOST_RECENT_VALUATION  \\\n",
       "0        1986-01-01                NaN                    NaN   \n",
       "1        1978-01-01                NaN                    NaN   \n",
       "2        2011-12-22        400000000.0           4.900000e+09   \n",
       "3        2004-01-01                NaN                    NaN   \n",
       "4        1919-01-01                NaN                    NaN   \n",
       "...             ...                ...                    ...   \n",
       "10706    2014-10-01                NaN                    NaN   \n",
       "10707    2009-02-02                NaN                    NaN   \n",
       "10708    2020-07-23                NaN                    NaN   \n",
       "10709    2002-09-28                NaN                    NaN   \n",
       "10710    2008-04-01                NaN                    NaN   \n",
       "\n",
       "                                               INVESTORS  KNOWN_TOTAL_FUNDING  \n",
       "0                                                    NaN                  NaN  \n",
       "1                                [\\n  \"Brand Capital\"\\n]                  NaN  \n",
       "2      [\\n  \"Eight Roads Ventures\",\\n  \"Greenoaks Cap...          899000000.0  \n",
       "3                                                    NaN                  NaN  \n",
       "4                                                    NaN                  NaN  \n",
       "...                                                  ...                  ...  \n",
       "10706                                                NaN                  NaN  \n",
       "10707                                                NaN                  NaN  \n",
       "10708                                                NaN                  NaN  \n",
       "10709                                                NaN                  NaN  \n",
       "10710                                                NaN                  NaN  \n",
       "\n",
       "[10711 rows x 9 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Getting a glimpse into the companies.csv file\n",
    "companies_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10635"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Comparing the total quantity with the distinct values of the column \"NAME\"\n",
    "#The dataset probably have duplicates, at least with the same name\n",
    "companies_df.NAME.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#No duplicates, so I'll just create a column \"index\" in the MySQL to create an easier identification column\n",
    "companies_df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyMySQL in c:\\users\\ritter\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (1.0.2)\n",
      "Collecting sqlalchemy\n",
      "  Downloading SQLAlchemy-1.4.42-cp310-cp310-win_amd64.whl (1.6 MB)\n",
      "     ---------------------------------------- 1.6/1.6 MB 2.1 MB/s eta 0:00:00\n",
      "Collecting greenlet!=0.4.17\n",
      "  Downloading greenlet-1.1.3.post0-cp310-cp310-win_amd64.whl (101 kB)\n",
      "     ---------------------------------------- 101.9/101.9 kB ? eta 0:00:00\n",
      "Installing collected packages: greenlet, sqlalchemy\n",
      "Successfully installed greenlet-1.1.3.post0 sqlalchemy-1.4.42\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#Installing the necessary libs to insert data into my MySQL database\n",
    "pip install PyMySQL sqlalchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymysql\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "#Creating the connection engine\n",
    "\n",
    "user = 'root'\n",
    "passw = 'mysql'\n",
    "host =  'localhost'\n",
    "port = 3306 \n",
    "schema = 'seven_apps'\n",
    "#database = 'dataBaseName'\n",
    "\n",
    "mydb = create_engine('mysql+pymysql://' + user + ':' + passw + '@' + host + ':' + str(port), echo=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SQL Script for the 'PEOPLE' table:\n",
    "\n",
    "```SQL\n",
    "CREATE TABLE IF NOT EXISTS 'seven_apps'.'PEOPLE' (\n",
    "  'PERSON_ID' VARCHAR(100) NOT NULL,\n",
    "  'COMPANY_NAME' VARCHAR(255) NULL,\n",
    "  'COMPANY_LI_NAME' VARCHAR(255) NULL,\n",
    "  'LAST_TITLE' VARCHAR(255) NULL,\n",
    "  'GROUP_START_DATE' DATE NULL,\n",
    "  'GROUP_END_DATE' DATE NULL);\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5391"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Inserting people data without the index column:\n",
    "people_df.to_sql(name='people', con=mydb, schema=schema, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SQL Script for the 'COMPANIES' table:\n",
    "\n",
    "```SQL\n",
    "CREATE TABLE IF NOT EXISTS 'seven_apps'.'COMPANIES' (\n",
    "  'INDEX' INT NOT NULL,\n",
    "  'NAME' VARCHAR(255) NULL,\n",
    "  'COMPANY_LINKEDIN_NAMES' TEXT NULL,\n",
    "  'DESCRIPTION' TEXT NULL,\n",
    "  'HEADCOUNT' DECIMAL NULL,\n",
    "  'FOUNDING_DATE' DATE NULL,\n",
    "  'MOST_RECENT_RAISE' DECIMAL NULL,\n",
    "  'MOST_RECENT_VALUATION' DECIMAL NULL,\n",
    "  'INVESTORS' TEXT NULL,\n",
    "  'KNOWN_TOTAL_FUNDING' DECIMAL NULL);\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10711"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Inserting companies data with the index column:\n",
    "companies_df.to_sql(name='companies', con=mydb, schema=schema, if_exists='append', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 1:\n",
    "\n",
    "What is the average total funding of all of the companies that the person with ID =\n",
    "‘92a52877-8d5d-41a6-950f-1b9c6574be7a’ has worked at?\n",
    "\n",
    "```SQL\n",
    "SELECT p.PERSON_ID, AVG(c.KNOWN_TOTAL_FUNDING) as avg_total_funding\n",
    "FROM people p\n",
    "INNER JOIN companies c\n",
    "ON UPPER(p.COMPANY_NAME) = UPPER(c.NAME)\n",
    "WHERE p.PERSON_ID = '92a52877-8d5d-41a6-950f-1b9c6574be7a';\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              PERSON_ID  avg_total_funding\n",
      "0  92a52877-8d5d-41a6-950f-1b9c6574be7a        108000000.0\n"
     ]
    }
   ],
   "source": [
    "question1_sql = '''SELECT p.PERSON_ID, AVG(c.KNOWN_TOTAL_FUNDING) as avg_total_funding\n",
    "FROM seven_apps.people p\n",
    "INNER JOIN seven_apps.companies c\n",
    "ON UPPER(p.COMPANY_NAME) = UPPER(c.NAME)\n",
    "WHERE p.PERSON_ID = '92a52877-8d5d-41a6-950f-1b9c6574be7a';'''\n",
    "\n",
    "print(pd.read_sql(sql=question1_sql, con=mydb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 2:\n",
    "\n",
    "How many companies are in the companies table that no people in the people table have worked\n",
    "for?\n",
    "\n",
    "```SQL\n",
    "SELECT count(*) AS quantity\n",
    "FROM seven_apps.companies c\n",
    "LEFT JOIN seven_apps.people p\n",
    "ON UPPER(c.NAME) = UPPER(p.COMPANY_NAME)\n",
    "WHERE p.COMPANY_NAME IS NULL\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   quantity\n",
      "0      9389\n"
     ]
    }
   ],
   "source": [
    "question2_sql = '''SELECT count(*) AS quantity\n",
    "FROM seven_apps.companies c\n",
    "LEFT JOIN seven_apps.people p\n",
    "ON UPPER(c.NAME) = UPPER(p.COMPANY_NAME)\n",
    "WHERE p.COMPANY_NAME IS NULL'''\n",
    "\n",
    "print(pd.read_sql(sql=question2_sql, con=mydb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 3:\n",
    "\n",
    "What are the ten most popular companies that these 1,000 people have worked for?\n",
    "\n",
    "```SQL\n",
    "SELECT COMPANY_NAME, count(*) as quantity\n",
    "FROM people \n",
    "GROUP BY COMPANY_NAME\n",
    "ORDER BY count(*) DESC\n",
    "LIMIT 10;\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 COMPANY_NAME  quantity\n",
      "0                   Microsoft        90\n",
      "1                      Amazon        81\n",
      "2           Intel Corporation        55\n",
      "3                      Google        45\n",
      "4                       Apple        24\n",
      "5  Hewlett Packard Enterprise        23\n",
      "6                    Facebook        21\n",
      "7           Texas Instruments        19\n",
      "8             Hewlett-Packard        17\n",
      "9                        Meta        15\n"
     ]
    }
   ],
   "source": [
    "question3_sql = '''SELECT COMPANY_NAME, count(*) as quantity\n",
    "FROM seven_apps.people \n",
    "GROUP BY COMPANY_NAME\n",
    "ORDER BY count(*) DESC\n",
    "LIMIT 10;'''\n",
    "\n",
    "print(pd.read_sql(sql=question3_sql, con=mydb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 4:\n",
    "\n",
    "Identify company founders in the people table.\n",
    "\n",
    "```SQL\n",
    "SELECT DISTINCT LAST_TITLE \n",
    "FROM seven_apps.people \n",
    "WHERE UPPER(last_title) like '%FOUNDER%';\n",
    "```\n",
    "\n",
    "Then identify the companies that these people have founded and list the top three largest companies by headcount, along with the name of that company and the person ID of the founder(s)\n",
    "\n",
    "```SQL\n",
    "SELECT \n",
    "\tc.NAME as COMPANY, \n",
    "    p.PERSON_ID as FOUNDER,\n",
    "    c.HEADCOUNT\n",
    "FROM seven_apps.people p\n",
    "INNER JOIN seven_apps.companies c\n",
    "on p.COMPANY_NAME = c.NAME\n",
    "WHERE UPPER(p.last_title) like '%FOUNDER%'\n",
    "GROUP BY c.NAME, p.PERSON_ID, c.HEADCOUNT\n",
    "ORDER BY c.HEADCOUNT DESC\n",
    "LIMIT 3;\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             COMPANY                               FOUNDER  HEADCOUNT\n",
      "0             Dafiti  bb0d8489-4360-4a94-bd3d-c079f75afc96     2907.0\n",
      "1  eBay for Business  a292842c-475e-4b4f-9671-fb09536c472e     1336.0\n",
      "2             UWorld  c6f69f63-c7d5-419f-af34-d0cccf544e18      439.0\n"
     ]
    }
   ],
   "source": [
    "question4_sql = '''SELECT \n",
    "\tc.NAME as COMPANY, \n",
    "    p.PERSON_ID as FOUNDER,\n",
    "    c.HEADCOUNT\n",
    "FROM seven_apps.people p\n",
    "INNER JOIN seven_apps.companies c\n",
    "on p.COMPANY_NAME = c.NAME\n",
    "WHERE UPPER(p.last_title) like '%%FOUNDER%%'\n",
    "GROUP BY c.NAME, p.PERSON_ID, c.HEADCOUNT\n",
    "ORDER BY c.HEADCOUNT DESC\n",
    "LIMIT 3;'''\n",
    "\n",
    "#Obs.: Added the double % just to escape the character on python\n",
    "\n",
    "print(pd.read_sql(sql=question4_sql, con=mydb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 5:\n",
    "\n",
    "For each person in the people table, identify their 2nd most recent job (if they only have 1 job,\n",
    "please exclude them).\n",
    "\n",
    "\n",
    "\n",
    "```SQL\n",
    "with seq as (\n",
    "\tSELECT \n",
    "\t\t*,\n",
    "\t\tRANK() \n",
    "\t\tover (partition by person_id, last_title order by group_start_date, group_end_date desc) as rnk\n",
    "\tFROM seven_apps.people\n",
    "    WHERE GROUP_END_DATE IS NOT NULL\n",
    ")\n",
    "SELECT b.person_id, b.last_title, b.group_start_date, b.group_end_date\n",
    "FROM seven_apps.people a\n",
    "INNER JOIN seq b\n",
    "ON a.PERSON_ID = b.PERSON_ID AND rnk = 2\n",
    "GROUP BY b.person_id, b.last_title, b.group_start_date, b.group_end_date;\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "What is the average duration in years of employment across everyone’s\n",
    "2nd most recent job? Additionally, how many people have had more than 1 job?\n",
    "\n",
    "\n",
    "\n",
    "```SQL\n",
    "with seq as (\n",
    "\tSELECT \n",
    "\t\t*,\n",
    "\t\tRANK() \n",
    "\t\tover (partition by person_id, last_title order by group_start_date, group_end_date desc) as rnk\n",
    "\tFROM seven_apps.people\n",
    "    WHERE GROUP_END_DATE IS NOT NULL\n",
    ")\n",
    "SELECT COUNT(distinct b.person_id), ROUND(AVG(datediff(b.group_end_date, b.group_start_date)/365),2) as average_years\n",
    "FROM seven_apps.people a\n",
    "INNER JOIN seq b\n",
    "ON a.PERSON_ID = b.PERSON_ID AND rnk = 2\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   COUNT(distinct b.person_id)  average_years\n",
      "0                          203           1.47\n"
     ]
    }
   ],
   "source": [
    "question5_sql = '''with seq as (\n",
    "\tSELECT \n",
    "\t\t*,\n",
    "\t\tRANK() \n",
    "\t\tover (partition by person_id, last_title order by group_start_date, group_end_date desc) as rnk\n",
    "\tFROM seven_apps.people\n",
    "    WHERE GROUP_END_DATE IS NOT NULL\n",
    ")\n",
    "SELECT COUNT(distinct b.person_id), ROUND(AVG(datediff(b.group_end_date, b.group_start_date)/365),2) as average_years\n",
    "FROM seven_apps.people a\n",
    "INNER JOIN seq b\n",
    "ON a.PERSON_ID = b.PERSON_ID AND rnk = 2'''\n",
    "\n",
    "print(pd.read_sql(sql=question5_sql, con=mydb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "af4a9f342819aa5d5127a31ba3d209ccb0f37828c0928aba4f4762bee341d4f6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
